{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rX8mhOLljYeM"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "BZSlp3DAjdYf"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6gHiH-I7uFa"
   },
   "source": [
    "#Improving Computer Vision Accuracy using Convolutions\n",
    "\n",
    "In the previous lessons you saw how to do fashion recognition using a Deep Neural Network (DNN) containing three layers -- the input layer (in the shape of the data), the output layer (in the shape of the desired output) and a hidden layer. You experimented with the impact of different sizes of hidden layer, number of training epochs etc on the final accuracy.\n",
    "\n",
    "For convenience, here's the entire code again. Run it and take a note of the test accuracy that is printed out at the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xcsRtq9OLorS",
    "outputId": "768e798d-463d-4a3b-e032-e7cfa94c4f8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6324 - accuracy: 0.7790\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3805 - accuracy: 0.8612\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3422 - accuracy: 0.8759\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3163 - accuracy: 0.8860\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2896 - accuracy: 0.8915\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8741\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images / 255.0\n",
    "test_images=test_images / 255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "test_loss = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zldEXSsF8Noz"
   },
   "source": [
    "Your accuracy is probably about 89% on training and 87% on validation...not bad...But how do you make that even better? One way is to use something called Convolutions. I'm not going to details on Convolutions here, but the ultimate concept is that they narrow down the content of the image to focus on specific, distinct, details. \n",
    "\n",
    "If you've ever done image processing using a filter (like this: https://en.wikipedia.org/wiki/Kernel_(image_processing)) then convolutions will look very familiar.\n",
    "\n",
    "In short, you take an array (usually 3x3 or 5x5) and pass it over the image. By changing the underlying pixels based on the formula within that matrix, you can do things like edge detection. So, for example, if you look at the above link, you'll see a 3x3 that is defined for edge detection where the middle cell is 8, and all of its neighbors are -1. In this case, for each pixel, you would multiply its value by 8, then subtract the value of each neighbor. Do this for every pixel, and you'll end up with a new image that has the edges enhanced.\n",
    "\n",
    "This is perfect for computer vision, because often it's features that can get highlighted like this that distinguish one item for another, and the amount of information needed is then much less...because you'll just train on the highlighted features.\n",
    "\n",
    "That's the concept of Convolutional Neural Networks. Add some layers to do convolution before you have the dense layers, and then the information going to the dense layers is more focussed, and possibly more accurate.\n",
    "\n",
    "Run the below code -- this is the same neural network as earlier, but this time with Convolutional layers added first. It will take longer, but look at the impact on the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C0tFgT1MMKi6",
    "outputId": "b9bb4b4a-1425-4458-f52b-436725321200"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 243,786\n",
      "Trainable params: 243,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 10s 2ms/step - loss: 0.5889 - accuracy: 0.7897\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2974 - accuracy: 0.8908\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2433 - accuracy: 0.9103\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2088 - accuracy: 0.9216\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1855 - accuracy: 0.9304\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2587 - accuracy: 0.9035\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "test_loss = model.evaluate(test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRLfZ0jt-fQI"
   },
   "source": [
    "It's likely gone up to about 93% on the training data and 91% on the validation data. \n",
    "\n",
    "That's significant, and a step in the right direction!\n",
    "\n",
    "Try running it for more epochs -- say about 20, and explore the results! But while the results might seem really good, the validation results may actually go down, due to something called 'overfitting' which will be discussed later. \n",
    "\n",
    "(In a nutshell, 'overfitting' occurs when the network learns the data from the training set really well, but it's too specialised to only that data, and as a result is less effective at seeing *other* data. For example, if all your life you only saw red shoes, then when you see a red shoe you would be very good at identifying it, but blue suade shoes might confuse you...and you know you should never mess with my blue suede shoes.)\n",
    "\n",
    "Then, look at the code again, and see, step by step how the Convolutions were built:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RaLX5cgI_JDb"
   },
   "source": [
    "Step 1 is to gather the data. You'll notice that there's a bit of a change here in that the training data needed to be reshaped. That's because the first convolution expects a single tensor containing everything, so instead of 60,000 28x28x1 items in a list, we have a single 4D list that is 60,000x28x28x1, and the same for the test images. If you don't do this, you'll get an error when training as the Convolutions do not recognize the shape. \n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images=test_images/255.0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SS_W_INc_kJQ"
   },
   "source": [
    "Next is to define your model. Now instead of the input layer at the top, you're going to add a Convolution. The parameters are:\n",
    "\n",
    "1. The number of convolutions you want to generate. Purely arbitrary, but good to start with something in the order of 32\n",
    "2. The size of the Convolution, in this case a 3x3 grid\n",
    "3. The activation function to use -- in this case we'll use relu, which you might recall is the equivalent of returning x when x>0, else returning 0\n",
    "4. In the first layer, the shape of the input data.\n",
    "\n",
    "You'll follow the Convolution with a MaxPooling layer which is then designed to compress the image, while maintaining the content of the features that were highlighted by the convlution. By specifying (2,2) for the MaxPooling, the effect is to quarter the size of the image. Without going into too much detail here, the idea is that it creates a 2x2 array of pixels, and picks the biggest one, thus turning 4 pixels into 1. It repeats this across the image, and in so doing halves the number of horizontal, and halves the number of vertical pixels, effectively reducing the image by 25%.\n",
    "\n",
    "You can call model.summary() to see the size and shape of the network, and you'll notice that after every MaxPooling layer, the image size is reduced in this way. \n",
    "\n",
    "\n",
    "```\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMorM6daADjA"
   },
   "source": [
    "Add another convolution\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1-x-kZF4_tC"
   },
   "source": [
    "Now flatten the output. After this you'll just have the same DNN structure as the non convolutional version\n",
    "\n",
    "```\n",
    "  tf.keras.layers.Flatten(),\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPtqR23uASjX"
   },
   "source": [
    "The same 128 dense layers, and 10 output layers as in the pre-convolution example:\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0GSsjUhAaSj"
   },
   "source": [
    "Now compile the model, call the fit method to do the training, and evaluate the loss and accuracy from the test set.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXx_LX3SAlFs"
   },
   "source": [
    "# Visualizing the Convolutions and Pooling\n",
    "\n",
    "This code will show us the convolutions graphically. The print (test_labels[;100]) shows us the first 100 labels in the test set, and you can see that the ones at index 0, index 23 and index 28 are all the same value (9). They're all shoes. Let's take a look at the result of running the convolution on each, and you'll begin to see common features between them emerge. Now, when the DNN is training on that data, it's working with a lot less, and it's perhaps finding a commonality between shoes based on this convolution/pooling combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "f-6nX4QsOku6",
    "outputId": "6b85ed93-6868-4c2c-b066-0808d6536878"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3 8 8 3 3 8 0 7\n",
      " 5 7 9 6 1 3 7 6 7 2 1 2 2 4 4 5 8 2 2 8 4 8 0 7 7 8 5 1 1 2 3 9 8 7 0 2 6\n",
      " 2 3 1 2 8 4 1 8 5 9 5 0 3 2 0 6 5 3 6 7 1 8 0 1 4 2]\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "9FGsHhv6JvDx",
    "outputId": "e52e56e2-86d9-4783-ca1d-d6baaaf47f51"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f, axarr = plt.subplots(3,4)\n",
    "FIRST_IMAGE=0\n",
    "SECOND_IMAGE=7\n",
    "THIRD_IMAGE=26\n",
    "CONVOLUTION_NUMBER = 1\n",
    "from tensorflow.keras import models\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
    "for x in range(0,4):\n",
    "  f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "  axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "  axarr[0,x].grid(False)\n",
    "  f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "  axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "  axarr[1,x].grid(False)\n",
    "  f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "  axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "  axarr[2,x].grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KVPZqgHo5Ux"
   },
   "source": [
    "EXERCISES\n",
    "\n",
    "1. Try editing the convolutions. Change the 32s to either 16 or 64. What impact will this have on accuracy and/or training time.\n",
    "\n",
    "2. Remove the final Convolution. What impact will this have on accuracy or training time?\n",
    "\n",
    "3. How about adding more Convolutions? What impact do you think this will have? Experiment with it.\n",
    "\n",
    "4. Remove all Convolutions but the first. What impact do you think this will have? Experiment with it. \n",
    "\n",
    "5. In the previous lesson you implemented a callback to check on the loss function and to cancel training once it hit a certain amount. See if you can implement that here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZpYRidBXpBPM",
    "outputId": "758c4064-ad17-4a6c-e21e-6b558dc1d725"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2964 - accuracy: 0.9119\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0502 - accuracy: 0.9847\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0295 - accuracy: 0.9907\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0176 - accuracy: 0.9944\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0120 - accuracy: 0.9962\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0075 - accuracy: 0.9977\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0070 - accuracy: 0.9976\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0046 - accuracy: 0.9986\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0028 - accuracy: 0.9991\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0541 - accuracy: 0.9876\n",
      "0.9876000285148621\n"
     ]
    }
   ],
   "source": [
    "# CONV 3x3x32\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=10)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "028XErVi5Wsw"
   },
   "source": [
    "CONV 3x3x32: Accuracy Accuracy 98.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GpEsNhbD5L3I",
    "outputId": "8ecddd38-5393-4c90-feb8-3c86a9780df1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2690 - accuracy: 0.9149\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0477 - accuracy: 0.9864\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0274 - accuracy: 0.9917\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0178 - accuracy: 0.9943\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0121 - accuracy: 0.9958\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0060 - accuracy: 0.9981\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0056 - accuracy: 0.9984\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0054 - accuracy: 0.9981\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0035 - accuracy: 0.9990\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0029 - accuracy: 0.9990\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0744 - accuracy: 0.9855\n",
      "0.9854999780654907\n"
     ]
    }
   ],
   "source": [
    "# CONV 3x3x64\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=10)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpipiPQ_6Gcr"
   },
   "source": [
    "CONV 3x3x64: Acc 98.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OzmvmE3F6Sd6",
    "outputId": "f4eb757e-e7ca-440d-c825-2193d03e1d85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3400 - accuracy: 0.8999\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0586 - accuracy: 0.9822\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0378 - accuracy: 0.9885\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0239 - accuracy: 0.9927\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0171 - accuracy: 0.9946\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0118 - accuracy: 0.9964\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0091 - accuracy: 0.9969\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0059 - accuracy: 0.9981\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0038 - accuracy: 0.9991\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0047 - accuracy: 0.9985\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0602 - accuracy: 0.9855\n",
      "0.9854999780654907\n"
     ]
    }
   ],
   "source": [
    "# CONV 3x3x16\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=10)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6MkrmZJi6qdt"
   },
   "source": [
    "CONV 3x3x16: Acc 98.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q4v1x4IF68eH",
    "outputId": "53cc4940-ba53-4cee-d61a-f7dff26027eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3148 - accuracy: 0.9048\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0469 - accuracy: 0.9855\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0323 - accuracy: 0.9898\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0210 - accuracy: 0.9927\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0170 - accuracy: 0.9942\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0122 - accuracy: 0.9958\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0085 - accuracy: 0.9975\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0078 - accuracy: 0.9973\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - accuracy: 0.9976\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0042 - accuracy: 0.9986\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0392 - accuracy: 0.9902\n",
      "0.9901999831199646\n"
     ]
    }
   ],
   "source": [
    "# CONV 3x3x32 2 times\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=10)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYGcEK9G7mh6"
   },
   "source": [
    "CONV 3x3x32 2 times: Acc = 99.0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y_Algl5e7skg",
    "outputId": "995c9d33-09b0-410e-bda7-40e989144b8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4289 - accuracy: 0.8777\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1216 - accuracy: 0.9654\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0785 - accuracy: 0.9771\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0548 - accuracy: 0.9838\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0422 - accuracy: 0.9870\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0330 - accuracy: 0.9902\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0249 - accuracy: 0.9925\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0199 - accuracy: 0.9948\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0165 - accuracy: 0.9948\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0144 - accuracy: 0.9956\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0829 - accuracy: 0.9773\n",
      "0.9772999882698059\n"
     ]
    }
   ],
   "source": [
    "# remove CONV\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=10)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXB1_mBG9ek8"
   },
   "source": [
    "Removal of CONV: Acc = 97.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "llTiFX_e9kHV",
    "outputId": "fc8fafb7-7b2f-4b04-9a07-ca10f96a0cbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3204 - accuracy: 0.9013\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0483 - accuracy: 0.9851\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0332 - accuracy: 0.9894\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0223 - accuracy: 0.9931\n",
      "\n",
      "Reached 99% accuracy so cancelling training!\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0302 - accuracy: 0.9910\n",
      "0.9909999966621399\n"
     ]
    }
   ],
   "source": [
    "# Callback implementation:\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('accuracy') >= 0.99:\n",
    "            print('\\nReached 99% accuracy so cancelling training!')\n",
    "            self.model.stop_training = True\n",
    "callbacks = myCallback()\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lh6M_l9cBhCJ",
    "outputId": "f6b1eda6-79dc-4e4b-b119-b69055916123"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               102528    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 113,386\n",
      "Trainable params: 113,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mg6Rir-EBiv_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Course 1 - Part 6 - Lesson 2 - Notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
